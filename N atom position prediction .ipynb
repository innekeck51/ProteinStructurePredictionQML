{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "'''first importing libraries'''\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "from tensorflow.python.keras.layers import Embedding, Conv1D, MaxPooling1D, Dropout, Conv2DTranspose, Lambda\r\n",
    "from tensorflow.python.keras import Sequential\r\n",
    "\r\n",
    "import tensorflow.keras.backend as K\r\n",
    "\r\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "\r\n",
    "import ast\r\n",
    "  \r\n",
    "# reading the data from the file\r\n",
    "with open('out_30') as f:\r\n",
    "    lines5 = f.readlines()\r\n",
    "    \r\n",
    "output2 = pd.DataFrame()\r\n",
    "\r\n",
    "for lines in lines5:\r\n",
    "    d = ast.literal_eval(lines)\r\n",
    "    output2 = output2.append(d, ignore_index=True)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "output2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                            evolutionary            id  \\\n",
       "0      [[0.0, 0.0, 0.037827352085354024, 0.0061887570...      1VBK_1_A   \n",
       "1      [[0.0, 0.4306620209059233, 0.00915564598168870...  2EUL_d2euld1   \n",
       "2      [[0.0, 0.0, 0.017991004497751123, 0.0, 0.0, 0....      1QGV_1_A   \n",
       "3      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  1H4V_d1h4vb1   \n",
       "4      [[0.0, 0.006058446186742694, 0.0, 0.0417951353...  1C4K_d1c4ka2   \n",
       "...                                                  ...           ...   \n",
       "10328  [[0.0, 0.0, 0.45999679333012666, 0.23608884817...      2C0K_1_A   \n",
       "10329  [[0.0, 0.0, 0.1413934426229508, 0.0, 0.0202702...  1LLA_d1llaa1   \n",
       "10330  [[0.0, 0.0, 0.013590619956327732, 0.0289709122...      1L2T_1_A   \n",
       "10331  [[0.0, 0.0, 0.0, 0.00045288335737528947, 0.005...      1BMX_1_A   \n",
       "10332  [[0.0, 0.0, 0.763157894736842, 0.0, 0.0, 0.0, ...  1BVS_d1bvsh1   \n",
       "\n",
       "                                                    mask  \\\n",
       "0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2      [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                  ...   \n",
       "10328  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "10329  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "10330  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "10331  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "10332  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                                 primary  \\\n",
       "0      [10, 11, 17, 17, 7, 17, 14, 19, 5, 3, 7, 5, 16...   \n",
       "1      [10, 0, 14, 3, 17, 8, 9, 16, 8, 0, 5, 19, 3, 1...   \n",
       "2      [10, 15, 19, 10, 9, 12, 6, 9, 6, 11, 5, 18, 13...   \n",
       "3      [3, 8, 5, 12, 2, 9, 19, 9, 7, 12, 9, 16, 3, 3,...   \n",
       "4      [12, 12, 4, 4, 8, 15, 9, 8, 3, 19, 17, 15, 14,...   \n",
       "...                                                  ...   \n",
       "10328  [10, 11, 15, 3, 3, 17, 11, 2, 7, 8, 14, 16, 18...   \n",
       "10329  [9, 6, 2, 8, 13, 7, 14, 7, 1, 6, 9, 4, 3, 13, ...   \n",
       "10330  [10, 7, 8, 9, 8, 11, 17, 16, 8, 16, 19, 8, 10,...   \n",
       "10331  [1, 15, 7, 9, 2, 7, 14, 13, 5, 12, 8, 3, 12, 4...   \n",
       "10332  [5, 11, 0, 17, 14, 5, 15, 17, 17, 3, 0, 9, 17,...   \n",
       "\n",
       "                                                tertiary  \n",
       "0      [[2342.7, 2429.1, 2536.5, 2640.6, 2749.3, 2812...  \n",
       "1      [[981.8, 1093.7, 1219.7, 1277.1, 1398.6, 1501....  \n",
       "2      [[0.0, 0.0, 0.0, -2556.0, -2660.5, -2681.4, -2...  \n",
       "3      [[-1267.2, -1264.0, -1328.6, -1265.6, -1322.3,...  \n",
       "4      [[7325.0, 7400.0, 7516.6, 7574.5, 7683.5, 7812...  \n",
       "...                                                  ...  \n",
       "10328  [[1026.3, 907.7, 915.5, 822.9, 805.8, 804.6, 8...  \n",
       "10329  [[5982.3, 5877.8, 5766.5, 5793.4, 5685.1, 5630...  \n",
       "10330  [[1147.5, 1211.3, 1364.2, 1420.1, 1563.7, 1585...  \n",
       "10331  [[2440.0, 2339.8, 2386.1, 2439.1, 2502.6, 2481...  \n",
       "10332  [[0.0, 0.0, 0.0, 10364.5, 10431.4, 10372.8, 10...  \n",
       "\n",
       "[10333 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evolutionary</th>\n",
       "      <th>id</th>\n",
       "      <th>mask</th>\n",
       "      <th>primary</th>\n",
       "      <th>tertiary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.0, 0.0, 0.037827352085354024, 0.0061887570...</td>\n",
       "      <td>1VBK_1_A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[10, 11, 17, 17, 7, 17, 14, 19, 5, 3, 7, 5, 16...</td>\n",
       "      <td>[[2342.7, 2429.1, 2536.5, 2640.6, 2749.3, 2812...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.0, 0.4306620209059233, 0.00915564598168870...</td>\n",
       "      <td>2EUL_d2euld1</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[10, 0, 14, 3, 17, 8, 9, 16, 8, 0, 5, 19, 3, 1...</td>\n",
       "      <td>[[981.8, 1093.7, 1219.7, 1277.1, 1398.6, 1501....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.0, 0.0, 0.017991004497751123, 0.0, 0.0, 0....</td>\n",
       "      <td>1QGV_1_A</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[10, 15, 19, 10, 9, 12, 6, 9, 6, 11, 5, 18, 13...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, -2556.0, -2660.5, -2681.4, -2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1H4V_d1h4vb1</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 8, 5, 12, 2, 9, 19, 9, 7, 12, 9, 16, 3, 3,...</td>\n",
       "      <td>[[-1267.2, -1264.0, -1328.6, -1265.6, -1322.3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.0, 0.006058446186742694, 0.0, 0.0417951353...</td>\n",
       "      <td>1C4K_d1c4ka2</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[12, 12, 4, 4, 8, 15, 9, 8, 3, 19, 17, 15, 14,...</td>\n",
       "      <td>[[7325.0, 7400.0, 7516.6, 7574.5, 7683.5, 7812...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10328</th>\n",
       "      <td>[[0.0, 0.0, 0.45999679333012666, 0.23608884817...</td>\n",
       "      <td>2C0K_1_A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[10, 11, 15, 3, 3, 17, 11, 2, 7, 8, 14, 16, 18...</td>\n",
       "      <td>[[1026.3, 907.7, 915.5, 822.9, 805.8, 804.6, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10329</th>\n",
       "      <td>[[0.0, 0.0, 0.1413934426229508, 0.0, 0.0202702...</td>\n",
       "      <td>1LLA_d1llaa1</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[9, 6, 2, 8, 13, 7, 14, 7, 1, 6, 9, 4, 3, 13, ...</td>\n",
       "      <td>[[5982.3, 5877.8, 5766.5, 5793.4, 5685.1, 5630...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10330</th>\n",
       "      <td>[[0.0, 0.0, 0.013590619956327732, 0.0289709122...</td>\n",
       "      <td>1L2T_1_A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[10, 7, 8, 9, 8, 11, 17, 16, 8, 16, 19, 8, 10,...</td>\n",
       "      <td>[[1147.5, 1211.3, 1364.2, 1420.1, 1563.7, 1585...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10331</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.00045288335737528947, 0.005...</td>\n",
       "      <td>1BMX_1_A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 15, 7, 9, 2, 7, 14, 13, 5, 12, 8, 3, 12, 4...</td>\n",
       "      <td>[[2440.0, 2339.8, 2386.1, 2439.1, 2502.6, 2481...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10332</th>\n",
       "      <td>[[0.0, 0.0, 0.763157894736842, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1BVS_d1bvsh1</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[5, 11, 0, 17, 14, 5, 15, 17, 17, 3, 0, 9, 17,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 10364.5, 10431.4, 10372.8, 10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10333 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_train = np.zeros((4267, 256))\n",
    "y_train = np.zeros((4267, 256, 3))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "def padarray(A, size):\n",
    "    t = size - len(A)\n",
    "    return np.pad(A, pad_width=(0, t), mode='constant')\n",
    "\n",
    "def padarray1(A, size):\n",
    "    t = size - len(A)\n",
    "    return np.pad(A, pad_width=(0.00, t), mode='constant')\n",
    "  \n",
    "# reading the data from the file\n",
    "with open('out_30') as f:\n",
    "    lines5t = f.readlines()\n",
    "\n",
    "i = 0\n",
    "for linest in lines5t:\n",
    "    dt = ast.literal_eval(linest)\n",
    "    valst = []\n",
    "    keyst = []\n",
    "    valst = (dt[\"primary\"])\n",
    "    mapst = (dt[\"mask\"])\n",
    "    \n",
    "    keyst = (dt[\"tertiary\"])\n",
    "    \n",
    "    if (len(valst) <= 256) and (0 not in mapst):\n",
    "        arrxt1 = np.array(valst)\n",
    "        arrxt1 = padarray(arrxt1, 256)\n",
    "        arrxt1 = arrxt1.astype('uint8')\n",
    "\n",
    "    \n",
    "        x_train[i] = arrxt1\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "        arryt1 = np.array(keyst)\n",
    "        arryt1 = arryt1.reshape(3*len(valst), 3)\n",
    "        at = np.array([0, 0, 0])\n",
    "        l = 0\n",
    "        while l < (3*256 - 3*len(valst)):\n",
    "            arryt1 = np.vstack((arryt1, at))\n",
    "            l += 1\n",
    "        \n",
    "        arryt1 = arryt1.astype('float32')\n",
    "    \n",
    "    \n",
    "        arry10t1 = arryt1[0]\n",
    "  \n",
    "    \n",
    "        u = 0\n",
    "        while u < len(arryt1):\n",
    "            arry10t1 = np.vstack((arry10t1, arryt1[u]))\n",
    "        \n",
    "        \n",
    "            u += 3\n",
    "    \n",
    "    \n",
    "        y_train[i] = arry10t1\n",
    "        i += 1\n",
    "        \n",
    "\n",
    "print(i)   \n",
    "    \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "'''creating contact maps for training dataset'''\n",
    "\n",
    "## first defined numpy matrixes to store contact maps.\n",
    "cmap_train = np.zeros((y_train.shape[0], y_train.shape[1], y_train.shape[1], 1))\n",
    "\n",
    "for i1 in range(y_train.shape[0]):    \n",
    "    for i2 in range(y_train.shape[1]):\n",
    "        \n",
    "        # if amino acid sequence ends, loop continues saving computing time.\n",
    "        if x_train[i1, i2] == 0:\n",
    "            continue\n",
    "        \n",
    "        for i3 in range(y_train.shape[1]):\n",
    "            \n",
    "            # if amino acid sequence ends, loop continues saving computing time.\n",
    "            if x_train[i1, i3] == 0:\n",
    "                continue\n",
    "            \n",
    "            # distance calculation and thresholding\n",
    "            d_sqr = (y_train[i1,i2,0]-y_train[i1,i3,0])**2 + (y_train[i1,i2,1]-y_train[i1,i3,1])**2 + (y_train[i1,i2,2]-y_train[i1,i3,2])**2\n",
    "            cmap_train[i1, i2, i3, 0] = (d_sqr**0.5) > 900 # 9 angstrom distance threshold (900 threshold value)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "x_test = np.zeros((21, 256))\n",
    "y_test = np.zeros((21, 256, 3))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "def padarray(A, size):\n",
    "    t = size - len(A)\n",
    "    return np.pad(A, pad_width=(0, t), mode='constant')\n",
    "\n",
    "def padarray1(A, size):\n",
    "    t = size - len(A)\n",
    "    return np.pad(A, pad_width=(0.00, t), mode='constant')\n",
    "  \n",
    "# reading the data from the file\n",
    "with open('test30') as f:\n",
    "    lines5tt = f.readlines()\n",
    "\n",
    "i = 0\n",
    "for linestt in lines5tt:\n",
    "    dtt = ast.literal_eval(linestt)\n",
    "    valstt = []\n",
    "    keystt = []\n",
    "    valstt = (dtt[\"primary\"])\n",
    "    mapstt = (dtt[\"mask\"])\n",
    "    \n",
    "    keystt = (dtt[\"tertiary\"])\n",
    "    \n",
    "    if (len(valstt) <= 256) and (0 not in mapstt):\n",
    "        arrxt1t = np.array(valstt)\n",
    "        arrxt1t = padarray(arrxt1t, 256)\n",
    "        arrxt1t = arrxt1t.astype('uint8')\n",
    "\n",
    "    \n",
    "        x_test[i] = arrxt1t\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "        arryt1t = np.array(keystt)\n",
    "        arryt1t = arryt1t.reshape(3*len(valstt), 3)\n",
    "        at = np.array([0, 0, 0])\n",
    "        l = 0\n",
    "        while l < (3*256 - 3*len(valstt)):\n",
    "            arryt1t = np.vstack((arryt1t, at))\n",
    "            l += 1\n",
    "        \n",
    "        arryt1t = arryt1t.astype('float32')\n",
    "    \n",
    "    \n",
    "        arry10t1t = arryt1t[0]\n",
    "  \n",
    "    \n",
    "        u = 0\n",
    "        while u < len(arryt1t):\n",
    "            arry10t1t = np.vstack((arry10t1t, arryt1t[u]))\n",
    "        \n",
    "        \n",
    "            u += 3\n",
    "    \n",
    "    \n",
    "        y_test[i] = arry10t1t\n",
    "        i += 1\n",
    "        \n",
    "\n",
    "print(i)   \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "'''creating contact maps for test dataset'''\n",
    "\n",
    "## first defined numpy matrixes to store contact maps.\n",
    "cmap_test = np.zeros((y_test.shape[0], y_test.shape[1], y_test.shape[1], 1))\n",
    "\n",
    "for i1 in range(y_test.shape[0]):\n",
    "    for i2 in range(y_test.shape[1]):\n",
    "        \n",
    "        # if amino acid sequence ends, loop continues saving computing time.\n",
    "        if x_test[i1, i2] == 0:\n",
    "            continue\n",
    "        \n",
    "        for i3 in range(y_test.shape[1]):\n",
    "            \n",
    "            # if amino acid sequence ends, loop continues saving computing time.\n",
    "            if x_test[i1, i3] == 0:\n",
    "                continue\n",
    "            \n",
    "            # distance calculation and thresholding\n",
    "            d_sqr = (y_test[i1,i2,0]-y_test[i1,i3,0])**2 + (y_test[i1,i2,1]-y_test[i1,i3,1])**2 + (y_test[i1,i2,2]-y_test[i1,i3,2])**2\n",
    "            cmap_test[i1, i2, i3, 0] = (d_sqr**0.5) > 900 # 9 angstrom distance threshold (900 threshold value)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.layers import Concatenate\n",
    "\n",
    "\n",
    "import pennylane as qml\n",
    "\n",
    "n_qubits = 7\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qnode(inputs, weights):\n",
    "    qml.templates.AmplitudeEmbedding(inputs, wires=range(n_qubits))\n",
    "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
    "\n",
    "\n",
    "\n",
    "n_layers = 1\n",
    "weight_shapes = {\"weights\": (n_layers, n_qubits)}\n",
    "qlayer = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "'''Section 1: input data embedding'''\n",
    "\n",
    "model.add( Embedding(21, 3, mask_zero=True, input_length=256) ) # embedding vector length is 3\n",
    "\n",
    "'''Section 2: encoder (first part of the network) with 1D operations'''\n",
    "\n",
    "model.add( Conv1D(64, 3, activation='relu', padding='same') )\n",
    "model.add( Dropout(0.25) )\n",
    "model.add( Lambda(lambda qlayer: concatenate([tf.math.real(qlayer), tf.math.imag(qlayer)])))\n",
    "model.add( Conv1D(64, 3, activation='relu', padding='same') )\n",
    "model.add( MaxPooling1D(2) )\n",
    "model.add( Conv1D(64, 3, activation='relu', padding='same') )\n",
    "model.add( Dropout(0.25) )\n",
    "model.add( Conv1D(64, 3, activation='relu', padding='same') )\n",
    "model.add( MaxPooling1D(2) )\n",
    "model.add( Conv1D(128, 3, activation='relu', padding='same') )\n",
    "model.add( Dropout(0.25) )\n",
    "model.add( Conv1D(128, 3, activation='relu', padding='same') )\n",
    "model.add( MaxPooling1D(2) )\n",
    "model.add( Conv1D(128, 3, activation='relu', padding='same') )\n",
    "model.add( Dropout(0.25) )\n",
    "model.add( Conv1D(128, 3, activation='relu', padding='same') )\n",
    "\n",
    "model.add( Conv1D(32, 1, activation='relu', padding='same') )\n",
    "model.add( Conv1D(4, 1, activation='relu', padding='same') )\n",
    "\n",
    "'''Section 3: middle part of the network, converting 1D data to 2D data'''\n",
    "\n",
    "def from1Dto2D(arg_in):\n",
    "    b_size = tf.shape(arg_in)[0] # getting batch size\n",
    "    \n",
    "    ## matrix multiplications are performed separately for each band.\n",
    "    # for band 0\n",
    "    b0_1 = tf.linalg.matmul(arg_in[:,:,0:1], tf.ones((b_size,1,32)))\n",
    "    b0_2 = tf.linalg.matmul(tf.ones((b_size,32,1)), arg_in[:,:,0:1], transpose_b=True)\n",
    "    # for band 1\n",
    "    b1_1 = tf.linalg.matmul(arg_in[:,:,1:2], tf.ones((b_size,1,32)))\n",
    "    b1_2 = tf.linalg.matmul(tf.ones((b_size,32,1)), arg_in[:,:,1:2], transpose_b=True)\n",
    "    # for band 2\n",
    "    b2_1 = tf.linalg.matmul(arg_in[:,:,2:3], tf.ones((b_size,1,32)))\n",
    "    b2_2 = tf.linalg.matmul(tf.ones((b_size,32,1)), arg_in[:,:,2:3], transpose_b=True)\n",
    "    # for band 3\n",
    "    b3_1 = tf.linalg.matmul(arg_in[:,:,3:4], tf.ones((b_size,1,32)))\n",
    "    b3_2 = tf.linalg.matmul(tf.ones((b_size,32,1)), arg_in[:,:,3:4], transpose_b=True)   \n",
    "    \n",
    "    return tf.stack((b0_1, b1_1, b2_1, b3_1, b0_2, b1_2, b2_2, b3_2), axis=-1)\n",
    "    \n",
    "\n",
    "model.add( Lambda(from1Dto2D) )\n",
    "\n",
    "'''Section 4: decoder (last part of the network) with 2D operations '''\n",
    "\n",
    "\n",
    "'''Section 4: decoder (last part of the network) with 2D operations '''\n",
    "\n",
    "model.add( Conv2DTranspose(64, (1, 1), activation='relu', padding='same') )\n",
    "model.add( Conv2DTranspose(64, (1, 1), activation='relu', padding='same') )\n",
    "\n",
    "model.add( Conv2DTranspose(128, (3, 3), activation='relu',  padding='same') )\n",
    "model.add( Dropout(0.5) )\n",
    "model.add( Conv2DTranspose(128, (3, 3), strides=(2, 2), activation='relu',  padding='same') )\n",
    "model.add( Conv2DTranspose(128, (3, 3), activation='relu',  padding='same') )\n",
    "model.add( Dropout(0.5) )\n",
    "model.add( Conv2DTranspose(128, (3, 3), strides=(2, 2), activation='relu',  padding='same') )\n",
    "model.add( Conv2DTranspose(64, (3, 3), activation='relu',  padding='same') )\n",
    "model.add( Dropout(0.5) )\n",
    "model.add( Conv2DTranspose(64, (3, 3), strides=(2, 2), activation='relu',  padding='same') )\n",
    "model.add( Conv2DTranspose(64, (3, 3), activation='relu',  padding='same') )\n",
    "model.add( Dropout(0.5) )\n",
    "model.add( Conv2DTranspose(64, (3, 3), activation='relu',  padding='same') )\n",
    "\n",
    "model.add( Conv2DTranspose(64, (1, 1), activation='relu', padding='same') )\n",
    "model.add( Conv2DTranspose(64, (1, 1), activation='relu', padding='same') )\n",
    "model.add( Conv2DTranspose(1, (1, 1), activation='relu', padding='same') ) # single unit because of single band output\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam') # setting loss and optimizer\n",
    "\n",
    "model.summary() # printing the model summary"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fit_h = model.fit(x_train, cmap_train, batch_size=100, epochs=600, verbose=1, shuffle=1, validation_data=(x_test,cmap_test))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "'''plotting loss curves'''\n",
    "\n",
    "plt.plot(fit_h.history['loss'])\n",
    "plt.plot(fit_h.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "'''prediction over the test dataset from the trained model '''\n",
    "\n",
    "pred_test = model.predict(x_test, batch_size=100)\n",
    "\n",
    "pred_test = pred_test > 0.9 # applying empirical threshold to extract binary contact maps\n",
    "\n",
    "print(pred_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "'''plot couple of predicted contact maps vs actual contact maps to see model prediction'''\n",
    "\n",
    "rand_idx = np.random.randint(0,cmap_test.shape[0]) # generation random index to choose random protein\n",
    "\n",
    "plt.imshow(pred_test[rand_idx,:,:,0])\n",
    "plt.title('Prediction 1')\n",
    "plt.show()\n",
    "plt.imshow(cmap_test[rand_idx,:,:,0])\n",
    "plt.title('Actual 1')\n",
    "plt.show()\n",
    "\n",
    "rand_idx = np.random.randint(0,cmap_test.shape[0]) # generation random index to choose random protein\n",
    "\n",
    "plt.imshow(pred_test[rand_idx,:,:,0])\n",
    "plt.title('Prediction 2')\n",
    "plt.show()\n",
    "plt.imshow(cmap_test[rand_idx,:,:,0])\n",
    "plt.title('Actual 2')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "amino = {\"A\":\"1\", \"C\":\"2\", \"D\":\"3\", \"E\":\"4\", \"F\":\"5\", \"G\":\"6\", \"H\":\"7\", \"I\":\"8\", \"K\":\"9\", \"L\":\"10\", \"M\":\"11\", \"N\":\"12\", \"P\":\"13\", \"Q\":\"14\", \"R\":\"15\", \"S\":\"16\", \"T\":\"17\", \"V\":\"18\", \"W\":\"19\", \"Y\":\"20\"}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Amino_list = x_test[0].tolist()\n",
    "\n",
    "\n",
    "er = \"\"\n",
    "\n",
    "\n",
    "t=0\n",
    "while t < len(num_list):\n",
    "    er += str([key for key, value in amino.items() if str(value) == str(num_list[t])])\n",
    "    \n",
    "    t += 1\n",
    "    \n",
    "er = er.replace(\"[\",\"\")\n",
    "er = er.replace(\"]\",\"\")\n",
    "er = er.replace(\"'\",\"\")\n",
    "\n",
    "n = 50\n",
    "chunks = [er[i:i+n] for i in range(0, len(er), n)]\n",
    "\n",
    "\n",
    "\n",
    "my_file=open(\"contact_map_N_atom.txt\",'a+')\n",
    "my_file.write('PFRMAT' +'\\t'+ 'RR')\n",
    "for chunk in chunks:\n",
    "    my_file.write('SEQRES' + '\\t' + chunk + '\\n')\n",
    "\n",
    "for i in range(0,128):\n",
    "    for j in range(i+4,128):\n",
    "      \n",
    "      my_file.write(str(i+1)+\" \"+ str(j+1)+\" \"+\"0 4 \"+ str(max(pred_test[0][i][j])).replace(\"False\", \"0\").replace(\"True\", \"1\") +\"\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}